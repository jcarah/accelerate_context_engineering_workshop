{
    "metrics": {
        "trajectory_accuracy": {
            "description": "Evaluates how closely the actual agent execution path matched the expected sequence of sub-agents.",
            "instruction": "Evaluate the agent's execution trajectory against the expected reference.",
            "criteria": {
                "Sequence": "Did the agent call the sub-agents/tools in the correct order?",
                "Completeness": "Were any required steps missed?",
                "Noise": "Were there unnecessary or hallucinated steps?"
            },
            "rating_scores": {
                "0": "The trajectory is completely different or empty.",
                "1": "Major deviations; key sub-agents were skipped or invoked in the wrong order.",
                "2": "Some correct sub-agents, but significant ordering issues or extra steps.",
                "3": "Mostly correct trajectory with minor deviations (e.g., one extra step or slight reordering).",
                "4": "The trajectory is logically equivalent to the reference, achieving the same outcome.",
                "5": "Perfect match with the expected reference trajectory."
            },
            "metric_type": "llm",
            "is_managed": false,
            "agents": ["customer_service"],
            "dataset_mapping": {
                "prompt": {
                    "source_column": "user_inputs"
                },
                "reference": {
                    "source_column": "reference_data:reference_trajectory"
                },
                "response": {
                    "source_column": "trace_summary"
                }
            }
        },
        "response_correctness": {
            "description": "Assess if the final response directly addresses the user's intent and is factually consistent with the tool outputs.",
            "is_managed": true,
            "managed_metric_name": "GENERAL_QUALITY",
            "agents": ["customer_service"],
            "dataset_mapping": {
                "prompt": {
                    "source_column": "user_inputs"
                },
                "response": {
                    "source_column": "final_response"
                }
            }
        },
        "tool_usage_accuracy": {
            "description": "Evaluates if the agent used the correct tools with the correct arguments to fulfill the user's request.",
            "instruction": "Assess whether the tool calls made by the agent were necessary, correct, and effective.",
            "criteria": {
                "Selection": "Did the agent choose the right tool for the task?",
                "Arguments": "Were the input arguments correct and complete?",
                "Outcome": "Did the tool call contribute to solving the user's problem?"
            },
            "rating_scores": {
                "0": "No tools used when needed, or completely wrong tools used.",
                "1": "Tool selection was wrong, or arguments were critically flawed.",
                "2": "Correct tool, but arguments had errors causing failure.",
                "3": "Correct tool and arguments, but minor efficiency issues.",
                "4": "Effective tool usage that moved the conversation forward.",
                "5": "Perfect tool usage with optimal arguments and flow."
            },
            "metric_type": "llm",
            "is_managed": false,
            "agents": ["customer_service"],
            "dataset_mapping": {
                "prompt": {
                    "source_column": "user_inputs"
                },
                "response": {
                    "source_column": "extracted_data:sub_agent_trace"
                },
                "tool_usage": {
                    "source_column": "extracted_data:tool_interactions"
                }
            }
        },
        "state_management_fidelity": {
            "description": "Checks if the agent correctly updated its internal state (e.g., customer profile) based on the interaction.",
            "instruction": "Check if the agent correctly parsed and stored information into its session state variables.",
            "criteria": {
                "Extraction": "Did the agent correctly extract entities (e.g., 'Tomato', '123') from the user input?",
                "Mapping": "Are these values mapped to the correct state keys?",
                "Accuracy": "Do the values match the expected reference state?"
            },
            "rating_scores": {
                "0": "State is empty or completely unrelated to the interaction.",
                "1": "Major errors in state capture; wrong entities or values.",
                "2": "Some correct state variables, but significant omissions.",
                "3": "Key variables captured correctly, but some minor details missed.",
                "4": "All critical state variables present and correct.",
                "5": "Perfect state capture, including nuances and optional fields."
            },
            "metric_type": "llm",
            "is_managed": false,
            "agents": ["customer_service"],
            "dataset_mapping": {
                "prompt": {
                    "source_column": "user_inputs"
                },
                "reference": {
                    "source_column": "reference_data:reference_state_variables"
                },
                "response": {
                    "source_column": "extracted_data:state_variables"
                }
            }
        }
    }
}
